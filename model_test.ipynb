{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"proccesed_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path to your dataset (replace with actual path if needed)\n",
    "def load_and_split_data(directory, validation_split=0.2, test_split=0.1, seed=123):\n",
    "    # Load the entire dataset\n",
    "    full_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "        directory,\n",
    "        seed=seed,\n",
    "        shuffle=True,\n",
    "        label_mode='categorical',\n",
    "        image_size=(224, 224),\n",
    "        batch_size=32)  # Adjust batch_size according to your needs\n",
    "\n",
    "    # Calculate the number of batches needed for each split\n",
    "    total_batches = len(full_dataset)\n",
    "    val_batches = int(total_batches * validation_split)\n",
    "    test_batches = int(total_batches * test_split)\n",
    "    train_batches = total_batches - val_batches - test_batches\n",
    "\n",
    "    # Split the dataset into train, validation, and test\n",
    "    train_dataset = full_dataset.take(train_batches)\n",
    "    test_dataset = full_dataset.skip(train_batches).take(test_batches)\n",
    "    validation_dataset = full_dataset.skip(train_batches + test_batches)\n",
    "\n",
    "    return train_dataset, validation_dataset, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8303 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "base_dir = 'proccesed_dataset'\n",
    "train_ds, val_ds, test_ds = load_and_split_data(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape, num_classes):\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "        layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        layers.RandomRotation(0.2),\n",
    "        layers.RandomZoom(0.2),\n",
    "        layers.RandomTranslation(height_factor=0.2, width_factor=0.2)\n",
    "    ])\n",
    "    \n",
    "    base_model = MobileNetV2(input_shape=input_shape,\n",
    "                            include_top=False,\n",
    "                            weights='imagenet')\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = data_augmentation(inputs)\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.0001,\n",
    "    decay_steps=100,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(input_shape=(224, 224, 3), num_classes=6)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 224, 224, 3)\n",
      "(32, 6)\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_ds.take(1):\n",
    "    print(images.shape)  # Should be (batch_size, 224, 224, 3)\n",
    "    print(labels.shape)  # Should be (batch_size, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccuracyThreshold(Callback):\n",
    "    def __init__(self, threshold=0.85):\n",
    "        super(AccuracyThreshold, self).__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_accuracy = logs.get(\"val_accuracy\")\n",
    "        if val_accuracy is not None:\n",
    "            if val_accuracy >= self.threshold:\n",
    "                print(f\"\\nReached {self.threshold * 100}% accuracy. Stopping training...\")\n",
    "                self.model.stop_training = True\n",
    "\n",
    "# Instantiate the custom callback with a threshold of 85% (0.85)\n",
    "accuracy_threshold_callback = AccuracyThreshold(threshold=0.85)\n",
    "\n",
    "early_stopping_val_acc = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "early_stopping_acc = EarlyStopping(\n",
    "    monitor='accuracy',\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "182/182 [==============================] - 44s 228ms/step - loss: 11.1024 - accuracy: 0.5067 - val_loss: 9.4562 - val_accuracy: 0.6023\n",
      "Epoch 2/60\n",
      "182/182 [==============================] - 40s 222ms/step - loss: 8.2642 - accuracy: 0.6324 - val_loss: 7.2225 - val_accuracy: 0.6478\n",
      "Epoch 3/60\n",
      "182/182 [==============================] - 41s 223ms/step - loss: 6.3798 - accuracy: 0.6688 - val_loss: 5.6753 - val_accuracy: 0.6630\n",
      "Epoch 4/60\n",
      "182/182 [==============================] - 41s 225ms/step - loss: 5.0640 - accuracy: 0.7014 - val_loss: 4.6078 - val_accuracy: 0.6685\n",
      "Epoch 5/60\n",
      "182/182 [==============================] - 40s 222ms/step - loss: 4.1222 - accuracy: 0.7215 - val_loss: 3.8161 - val_accuracy: 0.6837\n",
      "Epoch 6/60\n",
      "182/182 [==============================] - 41s 226ms/step - loss: 3.4539 - accuracy: 0.7306 - val_loss: 3.2625 - val_accuracy: 0.6818\n",
      "Epoch 7/60\n",
      "182/182 [==============================] - 41s 228ms/step - loss: 2.9439 - accuracy: 0.7426 - val_loss: 2.8319 - val_accuracy: 0.7007\n",
      "Epoch 8/60\n",
      "182/182 [==============================] - 41s 225ms/step - loss: 2.5687 - accuracy: 0.7584 - val_loss: 2.5142 - val_accuracy: 0.7043\n",
      "Epoch 9/60\n",
      "182/182 [==============================] - 42s 232ms/step - loss: 2.2797 - accuracy: 0.7546 - val_loss: 2.2709 - val_accuracy: 0.6982\n",
      "Epoch 10/60\n",
      "182/182 [==============================] - 41s 226ms/step - loss: 2.0504 - accuracy: 0.7694 - val_loss: 2.0822 - val_accuracy: 0.7037\n",
      "Epoch 11/60\n",
      "182/182 [==============================] - 42s 228ms/step - loss: 1.8716 - accuracy: 0.7764 - val_loss: 1.9296 - val_accuracy: 0.7037\n",
      "Epoch 12/60\n",
      "182/182 [==============================] - 41s 228ms/step - loss: 1.7324 - accuracy: 0.7783 - val_loss: 1.8004 - val_accuracy: 0.7110\n",
      "Epoch 13/60\n",
      "182/182 [==============================] - 42s 231ms/step - loss: 1.6156 - accuracy: 0.7881 - val_loss: 1.6988 - val_accuracy: 0.7086\n",
      "Epoch 14/60\n",
      "182/182 [==============================] - 42s 228ms/step - loss: 1.5160 - accuracy: 0.7926 - val_loss: 1.6295 - val_accuracy: 0.7116\n",
      "Epoch 15/60\n",
      "182/182 [==============================] - 43s 237ms/step - loss: 1.4435 - accuracy: 0.7969 - val_loss: 1.5496 - val_accuracy: 0.7158\n",
      "Epoch 16/60\n",
      "182/182 [==============================] - 42s 231ms/step - loss: 1.3742 - accuracy: 0.7977 - val_loss: 1.5068 - val_accuracy: 0.7128\n",
      "Epoch 17/60\n",
      "182/182 [==============================] - 42s 230ms/step - loss: 1.3208 - accuracy: 0.7958 - val_loss: 1.4389 - val_accuracy: 0.7171\n",
      "Epoch 18/60\n",
      "182/182 [==============================] - 42s 230ms/step - loss: 1.2691 - accuracy: 0.7996 - val_loss: 1.4058 - val_accuracy: 0.7177\n",
      "Epoch 19/60\n",
      "182/182 [==============================] - 42s 230ms/step - loss: 1.2273 - accuracy: 0.8092 - val_loss: 1.3799 - val_accuracy: 0.7177\n",
      "Epoch 20/60\n",
      "182/182 [==============================] - 41s 228ms/step - loss: 1.1942 - accuracy: 0.8072 - val_loss: 1.3562 - val_accuracy: 0.7110\n",
      "Epoch 21/60\n",
      "182/182 [==============================] - 42s 229ms/step - loss: 1.1599 - accuracy: 0.8130 - val_loss: 1.3191 - val_accuracy: 0.7189\n",
      "Epoch 22/60\n",
      "182/182 [==============================] - 42s 228ms/step - loss: 1.1317 - accuracy: 0.8128 - val_loss: 1.2924 - val_accuracy: 0.7195\n",
      "Epoch 23/60\n",
      "182/182 [==============================] - 43s 235ms/step - loss: 1.1118 - accuracy: 0.8123 - val_loss: 1.2772 - val_accuracy: 0.7158\n",
      "Epoch 24/60\n",
      "182/182 [==============================] - 42s 229ms/step - loss: 1.0829 - accuracy: 0.8209 - val_loss: 1.2476 - val_accuracy: 0.7256\n",
      "Epoch 25/60\n",
      "182/182 [==============================] - 42s 229ms/step - loss: 1.0707 - accuracy: 0.8178 - val_loss: 1.2458 - val_accuracy: 0.7171\n",
      "Epoch 26/60\n",
      "182/182 [==============================] - 43s 236ms/step - loss: 1.0528 - accuracy: 0.8209 - val_loss: 1.2382 - val_accuracy: 0.7104\n",
      "Epoch 27/60\n",
      "182/182 [==============================] - 42s 231ms/step - loss: 1.0387 - accuracy: 0.8175 - val_loss: 1.2172 - val_accuracy: 0.7158\n",
      "Epoch 28/60\n",
      "182/182 [==============================] - 41s 227ms/step - loss: 1.0279 - accuracy: 0.8218 - val_loss: 1.2221 - val_accuracy: 0.7140\n",
      "Epoch 29/60\n",
      "182/182 [==============================] - 42s 232ms/step - loss: 1.0124 - accuracy: 0.8231 - val_loss: 1.2038 - val_accuracy: 0.7189\n",
      "Epoch 30/60\n",
      "182/182 [==============================] - 42s 230ms/step - loss: 1.0006 - accuracy: 0.8230 - val_loss: 1.1895 - val_accuracy: 0.7225\n",
      "Epoch 31/60\n",
      "182/182 [==============================] - 41s 228ms/step - loss: 0.9919 - accuracy: 0.8249 - val_loss: 1.1800 - val_accuracy: 0.7183\n",
      "Epoch 32/60\n",
      "182/182 [==============================] - 42s 229ms/step - loss: 0.9800 - accuracy: 0.8317 - val_loss: 1.1745 - val_accuracy: 0.7195\n",
      "Epoch 33/60\n",
      "182/182 [==============================] - 42s 229ms/step - loss: 0.9716 - accuracy: 0.8307 - val_loss: 1.1741 - val_accuracy: 0.7207\n",
      "Epoch 34/60\n",
      "182/182 [==============================] - 42s 229ms/step - loss: 0.9601 - accuracy: 0.8321 - val_loss: 1.1702 - val_accuracy: 0.7165\n",
      "Epoch 35/60\n",
      "182/182 [==============================] - 42s 231ms/step - loss: 0.9544 - accuracy: 0.8343 - val_loss: 1.1613 - val_accuracy: 0.7201\n",
      "Epoch 36/60\n",
      "182/182 [==============================] - 41s 227ms/step - loss: 0.9479 - accuracy: 0.8343 - val_loss: 1.1701 - val_accuracy: 0.7110\n",
      "Epoch 37/60\n",
      "182/182 [==============================] - 43s 236ms/step - loss: 0.9468 - accuracy: 0.8297 - val_loss: 1.1516 - val_accuracy: 0.7177\n",
      "Epoch 38/60\n",
      "182/182 [==============================] - 42s 229ms/step - loss: 0.9405 - accuracy: 0.8340 - val_loss: 1.1457 - val_accuracy: 0.7201\n",
      "Epoch 39/60\n",
      "182/182 [==============================] - 43s 234ms/step - loss: 0.9366 - accuracy: 0.8331 - val_loss: 1.1375 - val_accuracy: 0.7219\n",
      "Epoch 40/60\n",
      "182/182 [==============================] - 63s 346ms/step - loss: 0.9316 - accuracy: 0.8310 - val_loss: 1.1467 - val_accuracy: 0.7158\n",
      "Epoch 41/60\n",
      "182/182 [==============================] - 74s 405ms/step - loss: 0.9281 - accuracy: 0.8334 - val_loss: 1.1481 - val_accuracy: 0.7158\n",
      "Epoch 42/60\n",
      "182/182 [==============================] - 49s 267ms/step - loss: 0.9244 - accuracy: 0.8333 - val_loss: 1.1401 - val_accuracy: 0.7165\n",
      "Epoch 43/60\n",
      "182/182 [==============================] - 102s 560ms/step - loss: 0.9224 - accuracy: 0.8348 - val_loss: 1.1324 - val_accuracy: 0.7183\n",
      "Epoch 44/60\n",
      "182/182 [==============================] - 55s 302ms/step - loss: 0.9132 - accuracy: 0.8369 - val_loss: 1.1209 - val_accuracy: 0.7274\n",
      "Epoch 45/60\n",
      "182/182 [==============================] - 52s 285ms/step - loss: 0.9122 - accuracy: 0.8381 - val_loss: 1.1337 - val_accuracy: 0.7171\n",
      "Epoch 46/60\n",
      "182/182 [==============================] - 57s 313ms/step - loss: 0.9075 - accuracy: 0.8338 - val_loss: 1.1210 - val_accuracy: 0.7231\n",
      "Epoch 47/60\n",
      "182/182 [==============================] - 77s 422ms/step - loss: 0.9063 - accuracy: 0.8381 - val_loss: 1.1238 - val_accuracy: 0.7177\n",
      "Epoch 48/60\n",
      "182/182 [==============================] - 82s 453ms/step - loss: 0.9087 - accuracy: 0.8350 - val_loss: 1.1171 - val_accuracy: 0.7237\n",
      "Epoch 49/60\n",
      "182/182 [==============================] - 42s 233ms/step - loss: 0.9056 - accuracy: 0.8384 - val_loss: 1.1323 - val_accuracy: 0.7134\n",
      "Epoch 50/60\n",
      "182/182 [==============================] - 42s 229ms/step - loss: 0.9032 - accuracy: 0.8396 - val_loss: 1.1155 - val_accuracy: 0.7237\n",
      "Epoch 51/60\n",
      "182/182 [==============================] - 43s 234ms/step - loss: 0.9029 - accuracy: 0.8367 - val_loss: 1.1168 - val_accuracy: 0.7195\n",
      "Epoch 52/60\n",
      "182/182 [==============================] - 79s 436ms/step - loss: 0.8989 - accuracy: 0.8386 - val_loss: 1.0993 - val_accuracy: 0.7292\n",
      "Epoch 53/60\n",
      "182/182 [==============================] - 42s 233ms/step - loss: 0.9013 - accuracy: 0.8391 - val_loss: 1.1187 - val_accuracy: 0.7165\n",
      "Epoch 54/60\n",
      "182/182 [==============================] - 44s 241ms/step - loss: 0.8934 - accuracy: 0.8417 - val_loss: 1.1073 - val_accuracy: 0.7225\n",
      "Epoch 55/60\n",
      "182/182 [==============================] - 43s 239ms/step - loss: 0.8939 - accuracy: 0.8405 - val_loss: 1.1136 - val_accuracy: 0.7207\n",
      "Epoch 56/60\n",
      "182/182 [==============================] - 43s 237ms/step - loss: 0.8951 - accuracy: 0.8413 - val_loss: 1.1113 - val_accuracy: 0.7195\n",
      "Epoch 57/60\n",
      "182/182 [==============================] - 44s 239ms/step - loss: 0.8926 - accuracy: 0.8377 - val_loss: 1.1028 - val_accuracy: 0.7231\n",
      "Epoch 58/60\n",
      "182/182 [==============================] - 43s 237ms/step - loss: 0.8861 - accuracy: 0.8456 - val_loss: 1.1131 - val_accuracy: 0.7225\n",
      "Epoch 59/60\n",
      "182/182 [==============================] - 42s 229ms/step - loss: 0.8914 - accuracy: 0.8422 - val_loss: 1.1142 - val_accuracy: 0.7158\n",
      "Epoch 60/60\n",
      "182/182 [==============================] - 43s 236ms/step - loss: 0.8847 - accuracy: 0.8451 - val_loss: 1.1032 - val_accuracy: 0.7237\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=60,\n",
    "    callbacks=[accuracy_threshold_callback,early_stopping_val_acc,early_stopping_acc] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 6s 168ms/step - loss: 1.0955 - accuracy: 0.7356\n",
      "Test accuracy: 0.7355769276618958\n",
      "Test loss: 1.0954515933990479\n"
     ]
    }
   ],
   "source": [
    "# Assuming test_ds is your test dataset\n",
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "print(\"Test accuracy:\", test_accuracy)\n",
    "print(\"Test loss:\", test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('model')  # Saves to HDF5 file (requires h5py installed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "history_df = pd.DataFrame(history.history)\n",
    "\n",
    "# Save to CSV\n",
    "history_df.to_csv('model_history.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trash_app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
